{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"GAN.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"metadata":{"id":"6668W1u4y1Xf","colab_type":"text"},"cell_type":"markdown","source":["# **Analysis of Generative Advarsarial Networks**\n","[Click here for the original paper by Ian Goodfellow](https://https://arxiv.org/pdf/1406.2661.pdf)\n","\n","\n","Generative Adversarial Networks are a set of models that basically learn to create synthetic data that is similar to input data it's given. In more formal terms, a GAN is a generative model that learns the probability distribution (or data distribution) of the training examples it is given. From this distribution, we can then create sample outputs.\n","\n","---\n","**Wine Sellers and fake supplier analogy:**\n","![alt text](http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1524648806/gan_network_eg_jcgooq.jpg)\n","\n","There are two major components within GANs: the generator and the discriminator. The shop owner in the example is known as a discriminator network and is usually a convolutional neural network (since GANs are mainly used for image tasks) which assigns a probability that the image is real.\n","\n"]},{"metadata":{"id":"3_WmrMLiziW_","colab_type":"text"},"cell_type":"markdown","source":["The forger is known as the generative network, and is also typically a convolutional neural network (with deconvolution layers). This network takes some noise vector and outputs an image. When training the generative network, it learns which areas of the image to improve/change so that the discriminator would have a harder time differentiating its generated images from the real ones.\n","\n","The generative network keeps producing images that are closer in appearance to the real images while the discriminative network is trying to determine the differences between real and fake images. The ultimate goal is to have a generative network that can produce images which are indistinguishable from the real ones."]},{"metadata":{"id":"mb3TFeuwzirw","colab_type":"text"},"cell_type":"markdown","source":["Mathematically, we think about a dataset of examples \n","x\n","1\n",",\n","…\n",",\n","x\n","n\n"," as samples from a true data distribution \n","p\n","(\n","x\n",")\n",". In the example image below, the blue region shows the part of the image space that, with a high probability (over some threshold) contains real images, and black dots indicate our data points (each is one image in our dataset). Now, our model also describes a distribution \n","^p\n","θ\n","(\n","x\n",")\n"," (green) that is defined implicitly by taking points from a unit Gaussian distribution (red) and mapping them through a (deterministic) neural network — our generative model (yellow). Our network is a function with parameters \n","θ\n",", and tweaking these parameters will tweak the generated distribution of images. Our goal then is to find parameters \n","θ\n"," that produce a distribution that closely matches the true data distribution . Therefore, you can imagine the green distribution starting out random and then the training process iteratively changing the parameters \n","θ\n"," to stretch and squeeze it to better match the blue distribution.\n"," \n"," ![alt text](https://blog.openai.com/content/images/2017/02/gen_models_diag_2.svg)\n"]},{"metadata":{"id":"9nfZlgPA4seR","colab_type":"text"},"cell_type":"markdown","source":["![alt text](https://github.com/adeshpande3/Generative-Adversarial-Networks/raw/384e9f9f7261c9b347979e6d1667986ac320db1e/Images/GAN1.png)\n","  The above figure clearly illustrates exact working of a typical GAN model.\n","  \n","  In this notebook, I am going to follow a simple tutorial to build a GAN model to generate digits based on training from MNIST dataset. Ideally, it should be able to fool the best discriminators( including humans)\n","  \n","Here’s what we’re going to need:\n","\n","Real MNIST training images\n","A generator network that takes in a random noise vector and produces a synthetic image\n","A discriminator network (a CNN) that learns to distinguish between real and synthetic images. You can think of it as just a binary classifier (1 for real image, 0 for fake)\n","An optimization procedure that jointly updates both networks through SGD. This is the tricky part as we need to train the generator network to fool the discriminator network, which means that we have unique gradient flows and labels.\n","Tensorflow - Our choice of Deep Learning framework"]},{"metadata":{"id":"vNR9zvb_2ico","colab_type":"code","colab":{}},"cell_type":"code","source":["#Lets get started by loading our basic dependencies\n","import tensorflow as tf\n","import random\n","import numpy as np\n","import matplotlib.pyplot as plt\n","%matplotlib inline"],"execution_count":0,"outputs":[]},{"metadata":{"id":"q_byF4NH-51L","colab_type":"text"},"cell_type":"markdown","source":["### Let's import MNIST dataset into our main memory\n","\n","We have imported Numpy to help with some matrices, the random library for generating numbers, and Matplotlib for visualizing our image data."]},{"metadata":{"id":"o7Xgm2Po36Lp","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":479},"outputId":"08cc124a-c4d4-4590-a8af-1ee6f35b6dd0","executionInfo":{"status":"ok","timestamp":1536472286101,"user_tz":-330,"elapsed":8853,"user":{"displayName":"Kamlesh Tiwari","photoUrl":"//lh6.googleusercontent.com/-J32Brj7ieRI/AAAAAAAAAAI/AAAAAAAAACA/Gy8R5nZ5IVU/s50-c-k-no/photo.jpg","userId":"112079790131595130000"}}},"cell_type":"code","source":["\n","from tensorflow.examples.tutorials.mnist import input_data\n","mnist = input_data.read_data_sets(\"MNIST_data/\")"],"execution_count":2,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From <ipython-input-2-bcab2bb76036>:3: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please write your own downloading logic.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use urllib or similar directly.\n","Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use tf.data to implement this functionality.\n","Extracting MNIST_data/train-images-idx3-ubyte.gz\n","Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use tf.data to implement this functionality.\n","Extracting MNIST_data/train-labels-idx1-ubyte.gz\n","Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n","Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n","Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n","Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"],"name":"stdout"}]},{"metadata":{"id":"jji1DnPI_YoT","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"c01006f9-3cfb-42d2-89a5-c978d4220524","executionInfo":{"status":"ok","timestamp":1536472367769,"user_tz":-330,"elapsed":1107,"user":{"displayName":"Kamlesh Tiwari","photoUrl":"//lh6.googleusercontent.com/-J32Brj7ieRI/AAAAAAAAAAI/AAAAAAAAACA/Gy8R5nZ5IVU/s50-c-k-no/photo.jpg","userId":"112079790131595130000"}}},"cell_type":"code","source":["x_train = mnist.train.images[:55000,:]\n","x_train.shape"],"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(55000, 784)"]},"metadata":{"tags":[]},"execution_count":4}]},{"metadata":{"id":"yaxrWCbh_loD","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":265},"outputId":"8f185217-b9df-447f-e005-05b82965c83d","executionInfo":{"status":"ok","timestamp":1536472382387,"user_tz":-330,"elapsed":1354,"user":{"displayName":"Kamlesh Tiwari","photoUrl":"//lh6.googleusercontent.com/-J32Brj7ieRI/AAAAAAAAAAI/AAAAAAAAACA/Gy8R5nZ5IVU/s50-c-k-no/photo.jpg","userId":"112079790131595130000"}}},"cell_type":"code","source":["#Let's have a look at a random image\n","RandomNum = random.randint(0,55000)\n","image = x_train[RandomNum].reshape([28,28])\n","plt.imshow(image, cmap=plt.get_cmap('gray_r'))\n","plt.show()"],"execution_count":6,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAPoAAAD4CAYAAADFJPs2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n","text/plain":["<matplotlib.figure.Figure at 0x7f522072c7b8>"]},"metadata":{"tags":[]}}]},{"metadata":{"id":"-TdxtX2HAbbr","colab_type":"text"},"cell_type":"markdown","source":["# Discriminator Network\n","It would be a convolutional neural network with input size 28x28x1.\n","The output will be a single scalar number activation that describes whether or not the input image is real or not."]},{"metadata":{"id":"1b51Cr94AAbD","colab_type":"code","colab":{}},"cell_type":"code","source":["def conv2d(x, W):\n","  return tf.nn.conv2d(input=x, filter=W, strides=[1, 1, 1, 1], padding='SAME')\n","\n","def avg_pool_2x2(x):\n","  return tf.nn.avg_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"9V68Kc6DBcs8","colab_type":"text"},"cell_type":"markdown","source":["To make this discriminator network, we will initialize our weight matrix(filter of size 5x5) with random weights. Output will have a depth of 8.\n","As with any convolutional neural network, this module is repeated, and then followed by a series of fully connected layers. At the end of the network, we do a final matrix multiply and return the activation value. For those of you comfortable with CNNs, this is just a simple binary classifier. Nothing fancy.\n","\n","This architecture for this network is based on Tensorflow's sample CNN classifier model that they have explained in detail here: https://www.tensorflow.org/tutorials/mnist/pros/"]},{"metadata":{"id":"Jb22EMO2BDh7","colab_type":"code","colab":{}},"cell_type":"code","source":["def discriminator(x_image, reuse=False):\n","    with tf.variable_scope('discriminator') as scope:\n","        if (reuse):\n","            tf.get_variable_scope().reuse_variables()\n","        #First Conv and Pool Layers\n","        W_conv1 = tf.get_variable('d_wconv1', [5, 5, 1, 8], initializer=tf.truncated_normal_initializer(stddev=0.02))\n","        b_conv1 = tf.get_variable('d_bconv1', [8], initializer=tf.constant_initializer(0))\n","        h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n","        h_pool1 = avg_pool_2x2(h_conv1)\n","\n","        #Second Conv and Pool Layers\n","        W_conv2 = tf.get_variable('d_wconv2', [5, 5, 8, 16], initializer=tf.truncated_normal_initializer(stddev=0.02))\n","        b_conv2 = tf.get_variable('d_bconv2', [16], initializer=tf.constant_initializer(0))\n","        h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n","        h_pool2 = avg_pool_2x2(h_conv2)\n","\n","        #First Fully Connected Layer\n","        W_fc1 = tf.get_variable('d_wfc1', [7 * 7 * 16, 32], initializer=tf.truncated_normal_initializer(stddev=0.02))\n","        b_fc1 = tf.get_variable('d_bfc1', [32], initializer=tf.constant_initializer(0))\n","        h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*16])\n","        h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n","\n","        #Second Fully Connected Layer\n","        W_fc2 = tf.get_variable('d_wfc2', [32, 1], initializer=tf.truncated_normal_initializer(stddev=0.02))\n","        b_fc2 = tf.get_variable('d_bfc2', [1], initializer=tf.constant_initializer(0))\n","\n","        #Final Layer\n","        y_conv=(tf.matmul(h_fc1, W_fc2) + b_fc2)\n","    return y_conv"],"execution_count":0,"outputs":[]},{"metadata":{"id":"0gAKJ3xLCQuM","colab_type":"text"},"cell_type":"markdown","source":["# Generator Network\n","Now that we have our discriminator defined, let’s take a look at the generator module. For this, we’ll be basing our model off the generator introduced in the DCGAN paper (link: https://arxiv.org/pdf/1511.06434v2.pdf). You can think of the generator as being a kind of reverse ConvNet. With CNNs, the goal is to transform a 2 or 3 dimensional matrix of pixel values into a single probability. A generator, however, seeks to take a d-dimensional noise vector and upsample it to become a 28 x 28 image. This upsampling is done through a convolutional transpose (or deconvolution) layer. ReLUs and Batch Norm are then used to stabilize the outputs of each layer.\n","\n","The structure of the generator is very similar to that of the discriminator, except we're calling the convolution transpose method, instead of the conv2d one.\n","\n","The conv transpose + relu + batch norm pipeline is repeated 4 times so that the output volume grows larger and larger until a 28 x 28 x 1 image is formed."]},{"metadata":{"id":"8eItdecyCzZM","colab_type":"code","colab":{}},"cell_type":"code","source":["\n","def generator(z, batch_size, z_dim, reuse=False):\n","    with tf.variable_scope('generator') as scope:\n","        if (reuse):\n","            tf.get_variable_scope().reuse_variables()\n","        g_dim = 64 #Number of filters of first layer of generator \n","        c_dim = 1 #Color dimension of output (MNIST is grayscale, so c_dim = 1 for us)\n","        s = 28 #Output size of the image\n","        s2, s4, s8, s16 = int(s/2), int(s/4), int(s/8), int(s/16) #We want to slowly upscale the image, so these values will help\n","                                                                  #make that change gradual.\n","\n","        h0 = tf.reshape(z, [batch_size, s16+1, s16+1, 25])\n","        h0 = tf.nn.relu(h0)\n","        #Dimensions of h0 = batch_size x 2 x 2 x 25\n","\n","        #First DeConv Layer\n","        output1_shape = [batch_size, s8, s8, g_dim*4]\n","        W_conv1 = tf.get_variable('g_wconv1', [5, 5, output1_shape[-1], int(h0.get_shape()[-1])], \n","                                  initializer=tf.truncated_normal_initializer(stddev=0.1))\n","        b_conv1 = tf.get_variable('g_bconv1', [output1_shape[-1]], initializer=tf.constant_initializer(.1))\n","        H_conv1 = tf.nn.conv2d_transpose(h0, W_conv1, output_shape=output1_shape, strides=[1, 2, 2, 1], padding='SAME')\n","        H_conv1 = tf.contrib.layers.batch_norm(inputs = H_conv1, center=True, scale=True, is_training=True, scope=\"g_bn1\")\n","        H_conv1 = tf.nn.relu(H_conv1)\n","        #Dimensions of H_conv1 = batch_size x 3 x 3 x 256\n","\n","        #Second DeConv Layer\n","        output2_shape = [batch_size, s4 - 1, s4 - 1, g_dim*2]\n","        W_conv2 = tf.get_variable('g_wconv2', [5, 5, output2_shape[-1], int(H_conv1.get_shape()[-1])], \n","                                  initializer=tf.truncated_normal_initializer(stddev=0.1))\n","        b_conv2 = tf.get_variable('g_bconv2', [output2_shape[-1]], initializer=tf.constant_initializer(.1))\n","        H_conv2 = tf.nn.conv2d_transpose(H_conv1, W_conv2, output_shape=output2_shape, strides=[1, 2, 2, 1], padding='SAME')\n","        H_conv2 = tf.contrib.layers.batch_norm(inputs = H_conv2, center=True, scale=True, is_training=True, scope=\"g_bn2\")\n","        H_conv2 = tf.nn.relu(H_conv2)\n","        #Dimensions of H_conv2 = batch_size x 6 x 6 x 128\n","\n","        #Third DeConv Layer\n","        output3_shape = [batch_size, s2 - 2, s2 - 2, g_dim*1]\n","        W_conv3 = tf.get_variable('g_wconv3', [5, 5, output3_shape[-1], int(H_conv2.get_shape()[-1])], \n","                                  initializer=tf.truncated_normal_initializer(stddev=0.1))\n","        b_conv3 = tf.get_variable('g_bconv3', [output3_shape[-1]], initializer=tf.constant_initializer(.1))\n","        H_conv3 = tf.nn.conv2d_transpose(H_conv2, W_conv3, output_shape=output3_shape, strides=[1, 2, 2, 1], padding='SAME')\n","        H_conv3 = tf.contrib.layers.batch_norm(inputs = H_conv3, center=True, scale=True, is_training=True, scope=\"g_bn3\")\n","        H_conv3 = tf.nn.relu(H_conv3)\n","        #Dimensions of H_conv3 = batch_size x 12 x 12 x 64\n","\n","        #Fourth DeConv Layer\n","        output4_shape = [batch_size, s, s, c_dim]\n","        W_conv4 = tf.get_variable('g_wconv4', [5, 5, output4_shape[-1], int(H_conv3.get_shape()[-1])], \n","                                  initializer=tf.truncated_normal_initializer(stddev=0.1))\n","        b_conv4 = tf.get_variable('g_bconv4', [output4_shape[-1]], initializer=tf.constant_initializer(.1))\n","        H_conv4 = tf.nn.conv2d_transpose(H_conv3, W_conv4, output_shape=output4_shape, strides=[1, 2, 2, 1], padding='VALID')\n","        H_conv4 = tf.nn.tanh(H_conv4)\n","        #Dimensions of H_conv4 = batch_size x 28 x 28 x 1\n","\n","    return H_conv4"],"execution_count":0,"outputs":[]},{"metadata":{"id":"A2tsVwA4DEQk","colab_type":"text"},"cell_type":"markdown","source":["# Generating Sample Image"]},{"metadata":{"id":"C7mTx3PIDg9s","colab_type":"code","colab":{}},"cell_type":"code","source":["\n","sess  =tf.Session()\n","z_dimensions = 100\n","z_test_placeholder = tf.placeholder(tf.float32, [None, z_dimensions])"],"execution_count":0,"outputs":[]},{"metadata":{"id":"sWXE-cytDqnM","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1034},"outputId":"32b565fc-8f35-4aa4-f6f2-573b76758cd2","executionInfo":{"status":"error","timestamp":1536473374780,"user_tz":-330,"elapsed":1069,"user":{"displayName":"Kamlesh Tiwari","photoUrl":"//lh6.googleusercontent.com/-J32Brj7ieRI/AAAAAAAAAAI/AAAAAAAAACA/Gy8R5nZ5IVU/s50-c-k-no/photo.jpg","userId":"112079790131595130000"}}},"cell_type":"code","source":["sample_image = generator(z_test_placeholder, 1, z_dimensions)\n","test_z = np.random.normal(-1, 1, [1,z_dimensions])"],"execution_count":23,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-23-adfffd0c117f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msample_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz_test_placeholder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz_dimensions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtest_z\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mz_dimensions\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-10-5293bb2540b1>\u001b[0m in \u001b[0;36mgenerator\u001b[0;34m(z, batch_size, z_dim, reuse)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0moutput1_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg_dim\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         W_conv1 = tf.get_variable('g_wconv1', [5, 5, output1_shape[-1], int(h0.get_shape()[-1])], \n\u001b[0;32m---> 19\u001b[0;31m                                   initializer=tf.truncated_normal_initializer(stddev=0.1))\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mb_conv1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'g_bconv1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0moutput1_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mH_conv1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2d_transpose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW_conv1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput1_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'SAME'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(name, shape, dtype, initializer, regularizer, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint, synchronization, aggregation)\u001b[0m\n\u001b[1;32m   1465\u001b[0m       \u001b[0mconstraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1466\u001b[0m       \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1467\u001b[0;31m       aggregation=aggregation)\n\u001b[0m\u001b[1;32m   1468\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1469\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(self, var_store, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint, synchronization, aggregation)\u001b[0m\n\u001b[1;32m   1215\u001b[0m           \u001b[0mconstraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m           \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m           aggregation=aggregation)\n\u001b[0m\u001b[1;32m   1218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m   def _get_partitioned_variable(self,\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint, synchronization, aggregation)\u001b[0m\n\u001b[1;32m    525\u001b[0m           \u001b[0mconstraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    526\u001b[0m           \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 527\u001b[0;31m           aggregation=aggregation)\n\u001b[0m\u001b[1;32m    528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m   def _get_partitioned_variable(self,\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36m_true_getter\u001b[0;34m(name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, constraint, synchronization, aggregation)\u001b[0m\n\u001b[1;32m    479\u001b[0m           \u001b[0mconstraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    480\u001b[0m           \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 481\u001b[0;31m           aggregation=aggregation)\n\u001b[0m\u001b[1;32m    482\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    483\u001b[0m     \u001b[0;31m# Set trainable value based on synchronization value.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36m_get_single_variable\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, partition_info, reuse, trainable, collections, caching_device, validate_shape, use_resource, constraint, synchronization, aggregation)\u001b[0m\n\u001b[1;32m    846\u001b[0m                          \u001b[0;34m\"reuse=tf.AUTO_REUSE in VarScope? \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    847\u001b[0m                          \"Originally defined at:\\n\\n%s\" % (\n\u001b[0;32m--> 848\u001b[0;31m                              name, \"\".join(traceback.format_list(tb))))\n\u001b[0m\u001b[1;32m    849\u001b[0m       \u001b[0mfound_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_vars\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_compatible_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfound_var\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Variable generator/g_wconv1 already exists, disallowed. Did you mean to set reuse=True or reuse=tf.AUTO_REUSE in VarScope? Originally defined at:\n\n  File \"<ipython-input-10-5293bb2540b1>\", line 19, in generator\n    initializer=tf.truncated_normal_initializer(stddev=0.1))\n  File \"<ipython-input-16-34363e93cd9b>\", line 2, in <module>\n    Gz = generator(z_placeholder, batch_size, z_dimensions) #Gz holds the generated images\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n"]}]},{"metadata":{"id":"-T6-nTH0D6JU","colab_type":"code","colab":{}},"cell_type":"code","source":["sess.run(tf.global_variables_initializer())\n","temp = (sess.run(sample_image, feed_dict={z_test_placeholder: test_z}))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"rFObQ-ItEACM","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":265},"outputId":"53e6e665-81cb-43ed-92c8-c4f2de515d84","executionInfo":{"status":"ok","timestamp":1536472784892,"user_tz":-330,"elapsed":1446,"user":{"displayName":"Kamlesh Tiwari","photoUrl":"//lh6.googleusercontent.com/-J32Brj7ieRI/AAAAAAAAAAI/AAAAAAAAACA/Gy8R5nZ5IVU/s50-c-k-no/photo.jpg","userId":"112079790131595130000"}}},"cell_type":"code","source":["my_i = temp.squeeze()\n","plt.imshow(my_i, cmap='gray_r')\n","plt.show()"],"execution_count":14,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAPoAAAD4CAYAAADFJPs2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n5IysdgAAAABJRU5ErkJggg==\n","text/plain":["<matplotlib.figure.Figure at 0x7f5224c407b8>"]},"metadata":{"tags":[]}}]},{"metadata":{"id":"b6fR8CGKEHDM","colab_type":"text"},"cell_type":"markdown","source":["### Let’s look at how we can make our generator better. Enter loss functions and optimization!"]},{"metadata":{"id":"udsMoky5EDSM","colab_type":"code","colab":{}},"cell_type":"code","source":["batch_size = 16\n","tf.reset_default_graph() #Since we changed our batch size (from 1 to 16), we need to reset our Tensorflow graph\n","\n","sess = tf.Session()\n","x_placeholder = tf.placeholder(\"float\", shape = [None,28,28,1]) #Placeholder for input images to the discriminator\n","z_placeholder = tf.placeholder(tf.float32, [None, z_dimensions]) #Placeholder for input noise vectors to the generator"],"execution_count":0,"outputs":[]},{"metadata":{"id":"PpiUHXQDEZP1","colab_type":"text"},"cell_type":"markdown","source":["One of the trickiest parts about understanding GANs is that the loss function is a little bit more complex than that of a traditional CNN classifiers (For those, a simple MSE  would do the job). A GAN can be thought of as a zero sum minimax game. The generator is constantly improving to produce more and more realistic images, while the discriminator is trying to get better and better at distinguishing between real and generated images. This means that we need to formulate loss functions that affect both networks. Let’s take a look at the inputs and outputs of our networks."]},{"metadata":{"id":"y67It-bOEM0b","colab_type":"code","colab":{}},"cell_type":"code","source":["Dx = discriminator(x_placeholder) #Dx will hold discriminator outputs (unnormalized) for the real MNIST images\n","Gz = generator(z_placeholder, batch_size, z_dimensions) #Gz holds the generated images\n","Dg = discriminator(Gz, reuse=True) #Dg will hold discriminator outputs (unnormalized) for generated images"],"execution_count":0,"outputs":[]},{"metadata":{"id":"5AMIDzvxFIh1","colab_type":"text"},"cell_type":"markdown","source":["We want the generator network to create images that will fool the discriminator. The generator wants the discriminator to output a 1 (positive example). Therefore, we want to compute the loss between the Dg and label of 1. This can be done through the tf.nn.sigmoid_cross_entropy_with_logits function. This means that the cross entropy loss will be taken between the two arguments. The \"with_logits\" component means that the function will operate on unscaled values. Basically, this means that instead of using a softmax function to squish the output activations to probability values from 0 to 1, we simply return the unscaled value of the matrix multiplication. Take a look at the last line of our discriminator. There's no softmax or sigmoid layer at the end.\n","\n","The reduce mean function just takes the mean value of all of the components in the matrixx returned by the cross entropy function. This is just a way of reducing the loss to a single scalar value, instead of a vector or matrix."]},{"metadata":{"id":"XQA1TRniEsiN","colab_type":"code","colab":{}},"cell_type":"code","source":["g_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=Dg, labels=tf.ones_like(Dg)))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"uLouiZP6FV2N","colab_type":"text"},"cell_type":"markdown","source":["discriminator’s point of view. Its goal is to just get the correct labels (output 1 for each MNIST digit and 0 for the generated ones). We’d like to compute the loss between Dx and the correct label of 1 as well as the loss between Dg and the correct label of 0."]},{"metadata":{"id":"GDoFXgEvFM2d","colab_type":"code","colab":{}},"cell_type":"code","source":["d_loss_real = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=Dx, labels=tf.ones_like(Dx)))\n","d_loss_fake = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=Dg, labels=tf.zeros_like(Dg)))\n","d_loss = d_loss_real + d_loss_fake"],"execution_count":0,"outputs":[]},{"metadata":{"id":"9AllhpGiGJJt","colab_type":"text"},"cell_type":"markdown","source":["Keep in mind that the optimizer for the generator network needs to only update the generator’s weights, not those of the discriminator. In order to make this distinction, we need to create 2 lists, one with the discriminator’s weights and one with the generator’s weights."]},{"metadata":{"id":"20_2bMKUFaG1","colab_type":"code","colab":{}},"cell_type":"code","source":["tvars = tf.trainable_variables()\n","d_vars = [var for var in tvars if 'd_' in var.name]\n","g_vars = [var for var in tvars if 'g_' in var.name]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"vxd2gYbjGVLt","colab_type":"code","colab":{}},"cell_type":"code","source":["#Adam seems to be the best SGD optimizer as it utilizes adaptive learning rates and momentum\n","with tf.variable_scope(tf.get_variable_scope(), reuse=False):\n","    trainerD = tf.train.AdamOptimizer().minimize(d_loss, var_list=d_vars)\n","    trainerG = tf.train.AdamOptimizer().minimize(g_loss, var_list=g_vars)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"fJH7pU7IGbz1","colab_type":"code","colab":{}},"cell_type":"code","source":["sess.run(tf.global_variables_initializer())\n","iterations = 3000\n","for i in range(iterations):\n","    z_batch = np.random.normal(-1, 1, size=[batch_size, z_dimensions])\n","    real_image_batch = mnist.train.next_batch(batch_size)\n","    real_image_batch = np.reshape(real_image_batch[0],[batch_size,28,28,1])\n","    _,dLoss = sess.run([trainerD, d_loss],feed_dict={z_placeholder:z_batch,x_placeholder:real_image_batch}) #Update the discriminator\n","    _,gLoss = sess.run([trainerG,g_loss],feed_dict={z_placeholder:z_batch}) #Update the generator"],"execution_count":0,"outputs":[]},{"metadata":{"id":"ZTjJ__ZXGg1t","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":282},"outputId":"565e23a1-d796-4263-c024-48dfa65870bc","executionInfo":{"status":"ok","timestamp":1536473372705,"user_tz":-330,"elapsed":1764,"user":{"displayName":"Kamlesh Tiwari","photoUrl":"//lh6.googleusercontent.com/-J32Brj7ieRI/AAAAAAAAAAI/AAAAAAAAACA/Gy8R5nZ5IVU/s50-c-k-no/photo.jpg","userId":"112079790131595130000"}}},"cell_type":"code","source":["sample_image = generator(z_placeholder, 1, z_dimensions, reuse=True)\n","z_batch = np.random.normal(-1, 1, size=[1, z_dimensions])\n","temp = (sess.run(sample_image, feed_dict={z_placeholder: z_batch}))\n","my_i = temp.squeeze()\n","plt.imshow(my_i, cmap='gray_r')"],"execution_count":22,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<matplotlib.image.AxesImage at 0x7f521bd50dd8>"]},"metadata":{"tags":[]},"execution_count":22},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAPoAAAD4CAYAAADFJPs2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n1pBKAAAAAElFTkSuQmCC\n","text/plain":["<matplotlib.figure.Figure at 0x7f521debdd30>"]},"metadata":{"tags":[]}}]}]}